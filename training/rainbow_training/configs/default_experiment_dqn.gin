#import hanabi_learning_environment.agents.rainbow.rainbow_agent
#import hanabi_learning_environment.agents.rainbow.run_experiment

# This configures the DQN Agent.
AGENT_CLASS = @DQNAgent
DQNAgent.gamma = 0.99
DQNAgent.update_horizon = 1
DQNAgent.min_replay_history = 500 # agent steps
DQNAgent.target_update_period = 500 # agent steps
DQNAgent.epsilon_train = 0.0
DQNAgent.epsilon_eval = 0.0
DQNAgent.epsilon_decay_period = 1000 # agent steps
DQNAgent.tf_device = '/gpu:0'  # '/cpu:*' use for non-GPU version

run_experiment.training_steps = 10000
run_experiment.num_iterations = 10005
run_experiment.checkpoint_every_n = 100
run_one_iteration.evaluate_every_n = 25

# Small Hanabi.
create_environment.game_type = 'Hanabi-Small-Seer'

create_agent.agent_type = 'DQN'
create_obs_stacker.history_size = 1

rainbow_template.layer_size=128
rainbow_template.num_layers=2

# Configure manual rewards and visibility
set_reward_flags.use_hint_reward    = False
set_reward_flags.use_play_reward    = False
set_reward_flags.use_discard_reward = False




